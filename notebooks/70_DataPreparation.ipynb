{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/cbslogo.jpg' width=\"30%\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## - Phase: Data  Preparation -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden die grundlegenden Daten für die Modellierung aufbereitet. Hierzu zählt die Aggregation der Ausleihvorgänge, das Enfernen von Ausreißern und Nullwerten sowie das Zusammenführen der Ausleih- und Wetterdaten. Abschließend werden die Trainings und Testdaten für die Modellierungsnotebooks erstellt. \n",
    "In den jeweiligen Modellierungsnotebooks werden die Daten für die verwendeten Modell aufbereitet und angewendet.\n",
    "\n",
    "Dieses Notebook nutzt die folgenden Dateien:\n",
    "    counts.pkl,\n",
    "    weather_raw.pkl,\n",
    "    weather_alt.pkl,\n",
    "    trips_weather.pkl.\n",
    "    \n",
    "In diesem Notebook werden die Dateien test.pkl und training.pkl erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import missingno as msgno\n",
    "from workalendar.core import Calendar\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "HOLIDAYS = DATA_PATH + 'Feiertage.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(DATA_PATH+'counts_enriched.pkl')\n",
    "df_trips_weather = pd.read_pickle(DATA_PATH+'trips_weather.pkl')\n",
    "df_weather_alt = pd.read_pickle (DATA_PATH+'weather_alt.pkl')\n",
    "df_weather_raw = pd.read_pickle(DATA_PATH+'weather_raw.pkl')\n",
    "df_count=pd.read_pickle(DATA_PATH+'counts.pkl')\n",
    "df_holiday_data = pd.read_excel(HOLIDAYS,header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>Member type</th>\n",
       "      <th>count_in</th>\n",
       "      <th>count_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>Member</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>Casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>Member</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>Casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>Member</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21131071</th>\n",
       "      <td>32225</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>11</td>\n",
       "      <td>Member</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21131072</th>\n",
       "      <td>32225</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>12</td>\n",
       "      <td>Casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21131073</th>\n",
       "      <td>32225</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>12</td>\n",
       "      <td>Member</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21131074</th>\n",
       "      <td>32225</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>13</td>\n",
       "      <td>Casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21131075</th>\n",
       "      <td>32225</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>13</td>\n",
       "      <td>Member</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21131076 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          station_id       date  hour Member type  count_in  count_out\n",
       "0              31000 2015-01-01    10      Member         1          1\n",
       "1              31000 2015-01-01    11      Casual         0          0\n",
       "2              31000 2015-01-01    11      Member         0          0\n",
       "3              31000 2015-01-01    12      Casual         0          0\n",
       "4              31000 2015-01-01    12      Member         0          0\n",
       "...              ...        ...   ...         ...       ...        ...\n",
       "21131071       32225 2017-12-10    11      Member         0          0\n",
       "21131072       32225 2017-12-10    12      Casual         0          0\n",
       "21131073       32225 2017-12-10    12      Member         0          0\n",
       "21131074       32225 2017-12-10    13      Casual         0          0\n",
       "21131075       32225 2017-12-10    13      Member         0          1\n",
       "\n",
       "[21131076 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem ersten Schritt sollen stationsunabhängige Vorhersagen getroffen werden. Daher wird das Datenset basierend auf Datum und Stunde aggregiert (df_total).\n",
    "Da anschließend ggf. noch stationsabhängige Prognosen entwickelt werden sollen, wird auch ein Datenset erstellt bei welchem die Daten basierend auf Datum, Stunde und Station aggregiert werden (df_total_station).\n",
    "Für beide Datensets wird anschließend die Data Preparation durchgeführt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregation der Daten basierend auf Datum und Stunde --> Stationen und Member Type werden nicht mitberücksichtigt\n",
    "df_total=df_count.groupby(by=['date', 'hour']).agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_station = df_count.groupby(by=['date', 'hour', 'station_id']).agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='count_out'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotten von Ausreißern\n",
    "sn.boxplot(x=df_total['count_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entfernen von Ausreißern --> Berechnet z-score um die Abweichung eines Wertes vom Mittelwert zu ermitteln. Entfernt werden alle Werte,\n",
    "# die einen z-score >3 haben, da hier die Abweichung besonders hoch ist.\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "z = np.abs(stats.zscore(df_total))\n",
    "\n",
    "threshold = 3\n",
    "df_total = df_total[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entfernen von Ausreißern\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "z = np.abs(stats.zscore(df_total_station))\n",
    "\n",
    "threshold = 3\n",
    "df_total_station = df_total_station[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_station.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='count_out'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.boxplot(x=df_total['count_out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während des Data Understanding wurden die Orginaldaten um Informationen zu Feiertagen und Wetter ergänzt. Da für das Prognosemodell aggregierte Daten benötigt werden, wurde auf die Rohdaten zurückgegriffen um die Aggregation zu vereinfachen. Die Informationen zu Wetter und Feiertagen müssen nun wieder ergänzt werden. Dies geschieht in den folgenden Schritten. Zuerst werden die beiden Wetter-Datensätze zusammengeführt und die Nullwerte aufgefüllt. Da man davon ausgehen kann, dass das Wetter innerhalb einiger Stunden nur geringen Schwankungen unterliegt, werden die fehlenden Werte mit der ffill Methode aufgefüllt. D.h. ein fehlender Wert wird mit dem Wert des vorhergehenden DAtensatzes aufgefüllt, sofern dieser vorhanden ist. Es wurde definiert, dass mayimal 3 fehlende Werte, d.h. 3 aufeinanderfolgende Stunden, aufgefüllt werden dürfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wetter-Datenset wird um Spalten mit Datum und Stunde ergänzt --> nötig um Wetterdaten und Ausleihdaten zusammenzufügen\n",
    "df_weather_raw['date'] = df_weather_raw['time_ts'].apply(lambda dt: pd.Timestamp(dt.date()))\n",
    "df_weather_raw['hour'] = df_weather_raw['time_ts'].apply(lambda dt: dt.time().hour)\n",
    "df_weather_raw = df_weather_raw.drop('time_ts', axis = 1)\n",
    "df_weather_raw = df_weather_raw.drop_duplicates(subset = ['date', 'hour'])\n",
    "\n",
    "#Die beiden Wetter-Datensätze werden zusammengeführt\n",
    "df_weather = df_weather_raw.combine_first(df_weather_alt)\n",
    "df_weather = df_weather.drop_duplicates(subset = ['date', 'hour'])\n",
    "\n",
    "# Nullwerte in den Wetterdaten auffüllen\n",
    "df_weather['precipitation']=df_weather['precipitation'].fillna(method='ffill', limit = 3)\n",
    "df_weather['winddirection'] = df_weather['winddirection'].fillna(method='ffill', limit =3)\n",
    "df_weather['windspeed'] = df_weather['windspeed'].fillna(method='ffill', limit =2)\n",
    "df_weather['pressure'] = df_weather['pressure'].fillna(method='ffill', limit =2)\n",
    "df_weather['dewpoint'] = df_weather['dewpoint'].fillna(method='ffill', limit =1)\n",
    "df_weather['humidity']=df_weather['humidity'].fillna(method='ffill', limit = 1)\n",
    "df_weather['temperature']=df_weather['temperature'].fillna(method='ffill', limit = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ergänzen um Feiertage\n",
    "df_total['day_of_week'] = df_total['date'].dt.day\n",
    "df_count_complete= pd.merge(df_total, df_holiday_data, left_on=df_total['date'], right_on=df_holiday_data['start_ts'], how='left').drop(['start_ts', 'key_0'], axis=1)\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=min(df_count_complete['date']), end= max(df_count_complete['date']))\n",
    "df_count_complete['Holiday'] = df_count_complete['date'].isin(holidays)\n",
    "\n",
    "df_total_station['day_of_week'] = df_total_station['date'].dt.day\n",
    "df_count_complete_station= pd.merge(df_total_station, df_holiday_data, left_on=df_total_station['date'], right_on=df_holiday_data['start_ts'], how='left').drop(['start_ts', 'key_0'], axis=1)\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=min(df_count_complete_station['date']), end= max(df_count_complete_station['date']))\n",
    "df_count_complete_station['Holiday'] = df_count_complete_station['date'].isin(holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ergänzen um Wetterdaten\n",
    "df_count_weather= pd.merge(df_count_complete, df_weather, on=['date', 'hour'], how='left')\n",
    "df_count_weather_station= pd.merge(df_count_complete_station, df_weather, on=['date', 'hour'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Löschen überflüssiger Spalten\n",
    "df_count_weather = df_count_weather.drop(['Reason'], axis=1)\n",
    "df_count_weather_station = df_count_weather_station.drop(['Reason'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Data Understanding hat gezeigt, dass die Ausleihzahlen abhängig vom Wochentag sind. Unter der Woche liegt ein anderes Ausleihmuster vor, als an Wochenenden und Feiertagen. Um diese Information im Prognosemodell berücksichtigen zu können werden Wochentage ergänzt und die Information bzgl. Arbeitstag und Wochenende extrahiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wochentage ergänzen\n",
    "df_count_weather['weekday'] = df_count_weather['date'].dt.day_name()\n",
    "df_count_weather_station['weekday'] = df_count_weather_station['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Workingday basierend auf Wochentagen erstellen (1 für Werktag, 0 für Wochenende)\n",
    "df_count_weather['workingday'] = df_count_weather['weekday'].replace(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'],1)\n",
    "df_count_weather['workingday'] = df_count_weather['workingday']. replace(['Saturday', 'Sunday'],0)\n",
    "\n",
    "df_count_weather_station['workingday'] = df_count_weather_station['weekday'].replace(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'],1)\n",
    "df_count_weather_station['workingday'] = df_count_weather_station['workingday']. replace(['Saturday', 'Sunday'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable workingday anpassen, wenn es sich bei Werktag um Feiertag handelt\n",
    "df_count_weather.loc[df_count_weather['Holiday'] == True, 'workingday'] = 0\n",
    "df_count_weather.loc[df_count_weather['Holiday']== False, 'workingday'] = 1\n",
    "\n",
    "df_count_weather_station.loc[df_count_weather_station['Holiday'] == True, 'workingday'] = 0\n",
    "df_count_weather_station.loc[df_count_weather_station['Holiday']== False, 'workingday'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da auch eine Saisonalität der Daten abhängig von der jeweiligen Jahreszeit vorliegt, werden auch Informationen über diese ergänzt. Hierbei werden Dezember, Januar und Februar zu Winter zusammengefasst; März, April und Mai zu Frühling; Juni, Juli, August zu Sommer und September, Oktober, November zu Herbst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather.loc[df_count_weather['date'].dt.month.apply(lambda x: x in [1,2,12]), 'Season']='Winter'\n",
    "df_count_weather.loc[df_count_weather['date'].dt.month.apply(lambda x: x in [3,4,5]), 'Season']='Spring'\n",
    "df_count_weather.loc[df_count_weather['date'].dt.month.apply(lambda x: x in [6,7,8]), 'Season']='Summer'\n",
    "df_count_weather.loc[df_count_weather['date'].dt.month.apply(lambda x: x in [9,10,11]), 'Season']='Fall'\n",
    "\n",
    "df_count_weather_station.loc[df_count_weather_station['date'].dt.month.apply(lambda x: x in [1,2,12]), 'Season']='Winter'\n",
    "df_count_weather_station.loc[df_count_weather_station['date'].dt.month.apply(lambda x: x in [3,4,5]), 'Season']='Spring'\n",
    "df_count_weather_station.loc[df_count_weather_station['date'].dt.month.apply(lambda x: x in [6,7,8]), 'Season']='Summer'\n",
    "df_count_weather_station.loc[df_count_weather_station['date'].dt.month.apply(lambda x: x in [9,10,11]), 'Season']='Fall'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein weiterer wichtiger Schritt der Datenaufbereitung ist das Prüfen und Behandeln von Null-Werten. Damit die Daten für die verschiedensten Algorithmen verwendet werden können dürfen diese keine Nullwerte enthalten. Oben wurden bereits die Nullwerte in den Wetterdaten aufgefüllt. Im Folgenden werden nun die aggregierten und um die Wetterwerte angereicherten Ausleihdaten auf vollständigkeit geprüft. Da es im Verhältnis zur Gesamtzahl der Datensätze nur eine geringe Anzahl an Nullwerten gibt, werden alle Zeilen mit Nullwerten gelöscht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             0\n",
       "hour             0\n",
       "count_in         0\n",
       "count_out        0\n",
       "day_of_week      0\n",
       "Holiday          0\n",
       "dewpoint         3\n",
       "humidity         3\n",
       "precipitation    3\n",
       "pressure         3\n",
       "temperature      3\n",
       "winddirection    3\n",
       "windspeed        3\n",
       "weekday          0\n",
       "workingday       0\n",
       "Season           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               0\n",
       "hour               0\n",
       "station_id         0\n",
       "count_in           0\n",
       "count_out          0\n",
       "day_of_week        0\n",
       "Holiday            0\n",
       "dewpoint         743\n",
       "humidity         743\n",
       "precipitation    743\n",
       "pressure         743\n",
       "temperature      743\n",
       "winddirection    743\n",
       "windspeed        743\n",
       "weekday            0\n",
       "workingday         0\n",
       "Season             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count_weather_station.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather = df_count_weather.dropna()\n",
    "df_count_weather_station = df_count_weather_station.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather.set_index(['date'], inplace = True)\n",
    "df_count_weather['year'] = [x.year for x in df_count_weather.index]\n",
    "\n",
    "df_count_weather_station.set_index(['date'], inplace = True)\n",
    "df_count_weather_station['year'] = [x.year for x in df_count_weather_station.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather.reset_index(['date'], inplace = True)\n",
    "df_count_weather_station.reset_index(['date'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Datenset enthält kategorische Variablen, wie z.B. Wochentag, Stunde oder Jahreszeit. Diese Variablen werden zwar als numerische Werte repräsentiert, haben aber alle das gleiche Gewicht. Um diese Variablen für die Modellierung verwenden zu können, werden mittels One-Hot Encoding Dummy-Variabeln erstellt. Für jeden eindeutigen Wert einer Variable wird eine Spalte erstellt. Diese enthält eine 1, wenn in der ursprünglichen Spalte dieser Wert enthalten war. Ansonsten werden die Felder mit Nullen gefüllt. Es entsteht somit ein Binär-Vektor für jedes einzelne Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = ['date', 'hour', 'weekday']\n",
    "for var in category_list:\n",
    "    df_count_weather[var] = df_count_weather[var].astype('category')\n",
    "\n",
    "for var in category_list:\n",
    "    df_count_weather_station[var] = df_count_weather_station[var].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather= pd.get_dummies(df_count_weather, columns=['Season'])\n",
    "#df_count_weather=pd.get_dummies(df_count_weather, columns =['month'], prefix='month')\n",
    "df_count_weather=pd.get_dummies(df_count_weather, columns =['hour'], prefix='hour')\n",
    "df_count_weather=pd.get_dummies(df_count_weather, columns =['weekday'])\n",
    "\n",
    "df_count_weather_station= pd.get_dummies(df_count_weather_station, columns=['Season'])\n",
    "#df_count_weather=pd.get_dummies(df_count_weather, columns =['month'], prefix='month')\n",
    "df_count_weather_station=pd.get_dummies(df_count_weather_station, columns =['hour'], prefix='hour')\n",
    "df_count_weather_station=pd.get_dummies(df_count_weather_station, columns =['weekday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Erstellen von Dummy-Variablen führt dazu, dass eine der erstellten Variablen eines Features mittels der anderen Variablen vorhergesagt werden kann. Es entsteht das Problem der Multikolinearität, sprich der Abhängigkeit unabhängiger (erklärender) Features. Dies kann bei einigen Modellen wie z.B. linerarer oder logistischer Regression zu Problemen führen. Gelöst werden kann die Multikolinearität, indem jeweils eine der erstellten Dummy-Variablen gelöscht wird (https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather=df_count_weather.drop(['Season_Winter', 'hour_23', 'weekday_Sunday'], axis=1)\n",
    "df_count_weather_station=df_count_weather_station.drop(['Season_Winter', 'hour_23', 'weekday_Sunday'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes werden nicht mehr benötigte Spalten gelöscht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather = df_count_weather.drop(['Holiday'], axis=1)\n",
    "df_count_weather_station = df_count_weather_station.drop(['Holiday'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschließend werden die aufbereiteten Daten als pickle-Datei exportiert bevor final die Trainings- und Testdaten für die Modellierung erstellt werden. Hierbei bilden die Daten aus den Jahren 2015 und 2016 die Trainingsdaten, die Daten aus 2017 werden als Testdaten verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather.to_pickle(DATA_PATH+'counts_prepared.pkl')\n",
    "df_count_weather_station.to_pickle(DATA_PATH+'counts_prepared_stations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [2015, 2016]\n",
    "\n",
    "dataTrain = df_count_weather.loc[df_count_weather['year'].isin(array)]\n",
    "dataTrain = dataTrain.sort_values(by=['date'])\n",
    "dataTest = df_count_weather.loc[df_count_weather['year']==2017]\n",
    "dataTest = dataTest.sort_values(by=['date'])\n",
    "\n",
    "datetimecol = dataTest['date']\n",
    "yLabels = df_count_weather[\"count_out\"]\n",
    "\n",
    "\n",
    "dataTrainStations = df_count_weather_station.loc[df_count_weather_station['year'].isin(array)]\n",
    "dataTrainStations = dataTrainStations.sort_values(by=['date'])\n",
    "dataTestStations = df_count_weather_station.loc[df_count_weather_station['year']==2017]\n",
    "dataTestStations = dataTestStations.sort_values(by=['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrainStations.to_pickle(DATA_PATH+'training_stations.pkl')\n",
    "dataTestStations.to_pickle(DATA_PATH+'test_stations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
