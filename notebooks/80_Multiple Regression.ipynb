{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/cbslogo.jpg' width=\"30%\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressionsverfahren  \n",
    "## - Phase: Data Modelling -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ziel\n",
    "Prognose der Ausleihvorgänge insgesamt für jeweils eine Stunde eines Tages mithilfe eines geeigneten Machine Learning Modells!\n",
    "\n",
    "Zielvariable: Ausleihvorgänge (count_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook nutzt die Dateien \n",
    "counts_prepared.pkl. \n",
    "In dem vorliegenden Notebook werden keine Dateien erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics \n",
    "import statsmodels.api as sm\n",
    "import matplotlib as plt \n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_weather = pd.read_pickle(DATA_PATH+'counts_prepared.pkl')\n",
    "df_count=pd.read_pickle(DATA_PATH+'counts_prepared.pkl')\n",
    "\n",
    "df_count.reset_index()\n",
    "df_count['count_out'].sum()\n",
    "df_count = df_count.drop(['count_in'], axis=1)\n",
    "df_count.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellen von Trainings- und Testdaten\n",
    "\n",
    "Trainingsdaten mit den Datensätzen von 2015 und 2016 werden erstellt \n",
    "Testdaten werden mit dem Datensatz von 2017 erstellt. \n",
    "\n",
    "Entnommen aus dem ***70_Data Preperation*** Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [2015, 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = df_count.loc[df_count['year'].isin(array)]\n",
    "dataTrain = dataTrain.sort_values(by=['date'])\n",
    "dataTest = df_count.loc[df_count['year']==2017]\n",
    "dataTest = dataTest.sort_values(by=['date'])\n",
    "\n",
    "datetimecol = dataTest['date']\n",
    "yLabels = df_count[\"count_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17401, 41) (17401,) (8560, 41) (8560,)\n"
     ]
    }
   ],
   "source": [
    "# Trennen von Trainings- und Testdaten in unabhängige Variablen (X) und abhängige Variable (count_out y)\n",
    "drop_cols = ['date', 'count_in', 'index']\n",
    "y_cols =['count_out']\n",
    "feature_cols = [col for col in df_count.columns if (col not in y_cols) & (col not in drop_cols)]\n",
    "\n",
    "X_train = dataTrain[feature_cols]\n",
    "X_test = dataTest[feature_cols]\n",
    "\n",
    "y_train = dataTrain['count_out']\n",
    "y_test = dataTest['count_out']\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch das Feature Scaling sollen die Daten so transformiert werden, dass deren Mittelwert der Verteilung bei 0 liegt und deren Standardabweichung bei 1. Dadurch soll sichergestellt werden, dass die Daten Standardnormalverteilt sind, was eine Voraussetzung für die Lineare Regression ist.    \n",
    "\n",
    "Quelle: Schritt 6: https://www.kdnuggets.com/2019/07/data-pre-processing-optimizing-regression-model-performance.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vor einer Regression sollten die Werte skaliert werden --> durch StandardScaler werden die Werte standaridsiert \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition der Kostenfunktion\n",
    "\n",
    "Diese Funktion wird später verwendet um die Messwerte RMSLE und R-Squared Value zu berechnen, um die Güte der Prognose zu bewerten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementierung des RMSLE\n",
    "def rmsle(y_test, y_pred):\n",
    "    rmsle = np.sqrt(metrics.mean_squared_log_error( y_test, y_pred ))\n",
    "    #msle = metrics.mean_squared_log_error(y_test, y_pred)\n",
    "    #rmse = math.sqrt(mse)\n",
    "    return (rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "def score_model(model):\n",
    "    \"\"\" \n",
    "    Fits a model using the training set, predicts using the test set, and then calculates \n",
    "    and reports goodness of fit metrics.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, yhat)\n",
    "    me = rmsle(y_test, yhat)\n",
    "    print(\"Results from {}: \\nr2={:0.3f} \\nRMSLE={:0.3f}\".format(model, r2,  me))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressionsmodell erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da bei der Aufteilung der Trainings- und Testdaten durch \"feature_cols\" alle Spalten außer \"count_out\", \"date\", \"count_in\" und \"Index\" betrachtet werden, wird keine nachfolgend keine reine lineare Regression erstellt sondern eine Multiple Lineare Regression. \n",
    "\n",
    "Es werden ebenso zwei Varianten darstellt, wie eine Lineare Regression in Python erstellt werden kann. \n",
    "Nachfolgend wird zum Vergleich noch eine einfache lineare Regression erstellt, welche als Unabhängige Variable X nur die Temperatur und nicht mehr alle Spalten verwendet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variante 1: Multiple Lineare Regression mit scikit-learn erstellen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 157.5653218168725\n",
      "Mean Squared Error: 48952.735047934984\n",
      "Root Mean Squared Error (RMSE): 221.252649809974\n",
      "R-Squared Value: 0.6420604920286261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanja\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in log1p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My RMSLE: 1.867908291805847\n"
     ]
    }
   ],
   "source": [
    "X = df_count_weather[feature_cols]\n",
    "y = df_count_weather.count_out\n",
    "\n",
    "#Instanziieren der Klasse \n",
    "lm = LinearRegression()\n",
    "\n",
    "#Modell trainieren \n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "#Vorhersage\n",
    "y_pred =lm.predict(X_test)\n",
    "\n",
    "#Metriken ausgeben\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "#R-Squared Wert berechnen\n",
    "print('R-Squared Value:', lm.score(X_test, y_test))\n",
    "\n",
    "#RMSLE berechen:\n",
    "\n",
    "#score_model(lm)\n",
    "#from sklearn.metrics import mean_squared_log_error\n",
    "#print(rmsle = np.sqrt(metrics.mean_squared_log_error( y_test, y_pred )))\n",
    "\n",
    "#Urspürngliche Berechnung mit der oben definierten Kostenfunktion für RMSLE funktionierte nicht. \n",
    "#Daher Berechnung wurde die Berechnung nach dem Code von https://towardsdatascience.com/metrics-and-python-850b60710e0c ausprobiert. \n",
    "\n",
    "import math\n",
    "def RMSLE(y_pred, y_test):\n",
    "    total = 0 \n",
    "    for k in range(len(y_pred)):\n",
    "        LPred= np.log1p(y_pred[k]+1)\n",
    "        LTarg = np.log1p(y_test[k] + 1)\n",
    "        if not (math.isnan(LPred)) and  not (math.isnan(LTarg)): \n",
    "            total = total + ((LPred-LTarg) **2)\n",
    "        \n",
    "    total = total / len(y_pred)        \n",
    "    return np.sqrt(total)\n",
    "print ('My RMSLE: ' + str(RMSLE(y_pred,y)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der MSE (Mean Squared Error) Wert sollte ein relativ kleiner Wert sein. </b>\n",
    "Der R-Squared Wert sollte ein Wert möglichst nahe an 1,0 sein. Ist der Wert sehr gering, heißt dass, das die unabhängigen X-Variablen nicht so gut dafür geeignet sind die abhängige y-Variable vorherzusagen. Ist der Wert nahe an 1 besitzt das Modell eine gute Anpassungsgüte. </>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5287391446868062"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accurancy berechnen\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy = cross_val_score(estimator = lm, X = X_train, y = y_train, cv =10)\n",
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Prognosemodell hat eine Vorhersagegenauigkeit von ca. 52%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17401</th>\n",
       "      <td>77</td>\n",
       "      <td>-67.745248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17424</th>\n",
       "      <td>46</td>\n",
       "      <td>23.843733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17423</th>\n",
       "      <td>60</td>\n",
       "      <td>122.434287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17422</th>\n",
       "      <td>91</td>\n",
       "      <td>211.978264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17421</th>\n",
       "      <td>110</td>\n",
       "      <td>315.290045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17420</th>\n",
       "      <td>162</td>\n",
       "      <td>487.082818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17419</th>\n",
       "      <td>184</td>\n",
       "      <td>710.825706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17417</th>\n",
       "      <td>390</td>\n",
       "      <td>586.986311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17416</th>\n",
       "      <td>546</td>\n",
       "      <td>450.887529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17415</th>\n",
       "      <td>522</td>\n",
       "      <td>375.716275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual   Predicted\n",
       "17401      77  -67.745248\n",
       "17424      46   23.843733\n",
       "17423      60  122.434287\n",
       "17422      91  211.978264\n",
       "17421     110  315.290045\n",
       "17420     162  487.082818\n",
       "17419     184  710.825706\n",
       "17417     390  586.986311\n",
       "17416     546  450.887529\n",
       "17415     522  375.716275"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Für ein paar Werte die Unterschiede zwischen Vorgehergesagt und Testdaten anschauen:\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df1 = df.head(25)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist hierbei exemplarisch zu erkennen, dass das Prognosemodell in einigen Fällen mit dem Vorhergesagten Wert extrem neben dem tatsächlichen Wert daneben liegt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variante 2: Mulitple lineare Regression mit 'statsmodel' Package erstellen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend wird die multiple lineare Regression noch mit einer anderen  Vorgehensweise erstellt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>count_out</td>    <th>  R-squared (uncentered):</th>       <td> -32.506</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td> -32.585</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>  -410.8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 04 Sep 2020</td> <th>  Prob (F-statistic):</th>            <td>  1.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:05:53</td>     <th>  Log-Likelihood:    </th>          <td>-1.2959e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 17401</td>      <th>  AIC:               </th>           <td>2.593e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 17360</td>      <th>  BIC:               </th>           <td>2.596e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    41</td>      <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>   -6.5077</td> <td>    3.155</td> <td>   -2.063</td> <td> 0.039</td> <td>  -12.692</td> <td>   -0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>   99.3858</td> <td>   43.232</td> <td>    2.299</td> <td> 0.022</td> <td>   14.646</td> <td>  184.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>  -62.8514</td> <td>   19.098</td> <td>   -3.291</td> <td> 0.001</td> <td> -100.286</td> <td>  -25.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>   -7.5484</td> <td>    3.261</td> <td>   -2.315</td> <td> 0.021</td> <td>  -13.939</td> <td>   -1.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>    7.8312</td> <td>    3.672</td> <td>    2.132</td> <td> 0.033</td> <td>    0.633</td> <td>   15.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>   -0.7805</td> <td>   38.010</td> <td>   -0.021</td> <td> 0.984</td> <td>  -75.284</td> <td>   73.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>  -16.9234</td> <td>    3.495</td> <td>   -4.842</td> <td> 0.000</td> <td>  -23.775</td> <td>  -10.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>   10.9524</td> <td>    3.269</td> <td>    3.350</td> <td> 0.001</td> <td>    4.545</td> <td>   17.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    7.3744</td> <td>    3.168</td> <td>    2.328</td> <td> 0.020</td> <td>    1.165</td> <td>   13.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>   41.9585</td> <td>    5.068</td> <td>    8.279</td> <td> 0.000</td> <td>   32.025</td> <td>   51.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>   42.8546</td> <td>    4.683</td> <td>    9.150</td> <td> 0.000</td> <td>   33.675</td> <td>   52.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>   37.4378</td> <td>    6.680</td> <td>    5.605</td> <td> 0.000</td> <td>   24.345</td> <td>   50.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>   -9.5727</td> <td>    4.363</td> <td>   -2.194</td> <td> 0.028</td> <td>  -18.124</td> <td>   -1.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>  -14.1392</td> <td>    4.377</td> <td>   -3.231</td> <td> 0.001</td> <td>  -22.718</td> <td>   -5.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>  -16.2870</td> <td>    4.397</td> <td>   -3.704</td> <td> 0.000</td> <td>  -24.905</td> <td>   -7.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th> <td>  -17.4889</td> <td>    4.422</td> <td>   -3.955</td> <td> 0.000</td> <td>  -26.156</td> <td>   -8.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th> <td>  -16.6288</td> <td>    4.441</td> <td>   -3.744</td> <td> 0.000</td> <td>  -25.334</td> <td>   -7.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th> <td>   -6.7826</td> <td>    4.457</td> <td>   -1.522</td> <td> 0.128</td> <td>  -15.518</td> <td>    1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th> <td>   19.5967</td> <td>    4.473</td> <td>    4.381</td> <td> 0.000</td> <td>   10.828</td> <td>   28.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th> <td>   83.2918</td> <td>    4.493</td> <td>   18.540</td> <td> 0.000</td> <td>   74.486</td> <td>   92.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th> <td>  136.1515</td> <td>    4.503</td> <td>   30.237</td> <td> 0.000</td> <td>  127.325</td> <td>  144.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th> <td>   74.4752</td> <td>    4.517</td> <td>   16.488</td> <td> 0.000</td> <td>   65.621</td> <td>   83.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th> <td>   57.3899</td> <td>    4.531</td> <td>   12.666</td> <td> 0.000</td> <td>   48.509</td> <td>   66.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th> <td>   71.5555</td> <td>    4.541</td> <td>   15.758</td> <td> 0.000</td> <td>   62.655</td> <td>   80.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th> <td>   87.5478</td> <td>    4.545</td> <td>   19.262</td> <td> 0.000</td> <td>   78.639</td> <td>   96.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th> <td>   86.8657</td> <td>    4.537</td> <td>   19.146</td> <td> 0.000</td> <td>   77.973</td> <td>   95.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th> <td>   82.1481</td> <td>    4.514</td> <td>   18.200</td> <td> 0.000</td> <td>   73.301</td> <td>   90.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th> <td>   88.8719</td> <td>    4.472</td> <td>   19.871</td> <td> 0.000</td> <td>   80.106</td> <td>   97.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th> <td>  114.8206</td> <td>    4.435</td> <td>   25.889</td> <td> 0.000</td> <td>  106.127</td> <td>  123.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th> <td>  148.9165</td> <td>    4.274</td> <td>   34.843</td> <td> 0.000</td> <td>  140.539</td> <td>  157.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th> <td>  134.3200</td> <td>    4.324</td> <td>   31.066</td> <td> 0.000</td> <td>  125.845</td> <td>  142.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th> <td>   88.6181</td> <td>    4.367</td> <td>   20.294</td> <td> 0.000</td> <td>   80.059</td> <td>   97.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th> <td>   53.8981</td> <td>    4.362</td> <td>   12.356</td> <td> 0.000</td> <td>   45.348</td> <td>   62.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th> <td>   31.4560</td> <td>    4.362</td> <td>    7.211</td> <td> 0.000</td> <td>   22.905</td> <td>   40.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th> <td>   15.6016</td> <td>    4.361</td> <td>    3.577</td> <td> 0.000</td> <td>    7.053</td> <td>   24.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th> <td>   17.5696</td> <td>    4.142</td> <td>    4.242</td> <td> 0.000</td> <td>    9.450</td> <td>   25.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th> <td>    7.8440</td> <td>    4.197</td> <td>    1.869</td> <td> 0.062</td> <td>   -0.383</td> <td>   16.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th> <td>    4.3529</td> <td>    4.131</td> <td>    1.054</td> <td> 0.292</td> <td>   -3.744</td> <td>   12.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th> <td>   11.6014</td> <td>    4.136</td> <td>    2.805</td> <td> 0.005</td> <td>    3.495</td> <td>   19.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th> <td>   10.0786</td> <td>    4.121</td> <td>    2.445</td> <td> 0.014</td> <td>    2.000</td> <td>   18.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th> <td>   15.7346</td> <td>    4.121</td> <td>    3.818</td> <td> 0.000</td> <td>    7.657</td> <td>   23.812</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>593.168</td> <th>  Durbin-Watson:     </th> <td>   0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1434.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.169</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.365</td>  <th>  Cond. No.          </th> <td>    31.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:              count_out   R-squared (uncentered):                 -32.506\n",
       "Model:                            OLS   Adj. R-squared (uncentered):            -32.585\n",
       "Method:                 Least Squares   F-statistic:                             -410.8\n",
       "Date:                Fri, 04 Sep 2020   Prob (F-statistic):                        1.00\n",
       "Time:                        09:05:53   Log-Likelihood:                     -1.2959e+05\n",
       "No. Observations:               17401   AIC:                                  2.593e+05\n",
       "Df Residuals:                   17360   BIC:                                  2.596e+05\n",
       "Df Model:                          41                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -6.5077      3.155     -2.063      0.039     -12.692      -0.324\n",
       "x2            99.3858     43.232      2.299      0.022      14.646     184.125\n",
       "x3           -62.8514     19.098     -3.291      0.001    -100.286     -25.417\n",
       "x4            -7.5484      3.261     -2.315      0.021     -13.939      -1.157\n",
       "x5             7.8312      3.672      2.132      0.033       0.633      15.029\n",
       "x6            -0.7805     38.010     -0.021      0.984     -75.284      73.723\n",
       "x7           -16.9234      3.495     -4.842      0.000     -23.775     -10.072\n",
       "x8            10.9524      3.269      3.350      0.001       4.545      17.360\n",
       "x9             7.3744      3.168      2.328      0.020       1.165      13.584\n",
       "x10           41.9585      5.068      8.279      0.000      32.025      51.892\n",
       "x11           42.8546      4.683      9.150      0.000      33.675      52.034\n",
       "x12           37.4378      6.680      5.605      0.000      24.345      50.531\n",
       "x13           -9.5727      4.363     -2.194      0.028     -18.124      -1.021\n",
       "x14          -14.1392      4.377     -3.231      0.001     -22.718      -5.560\n",
       "x15          -16.2870      4.397     -3.704      0.000     -24.905      -7.669\n",
       "x16          -17.4889      4.422     -3.955      0.000     -26.156      -8.821\n",
       "x17          -16.6288      4.441     -3.744      0.000     -25.334      -7.924\n",
       "x18           -6.7826      4.457     -1.522      0.128     -15.518       1.953\n",
       "x19           19.5967      4.473      4.381      0.000      10.828      28.365\n",
       "x20           83.2918      4.493     18.540      0.000      74.486      92.098\n",
       "x21          136.1515      4.503     30.237      0.000     127.325     144.977\n",
       "x22           74.4752      4.517     16.488      0.000      65.621      83.329\n",
       "x23           57.3899      4.531     12.666      0.000      48.509      66.271\n",
       "x24           71.5555      4.541     15.758      0.000      62.655      80.456\n",
       "x25           87.5478      4.545     19.262      0.000      78.639      96.457\n",
       "x26           86.8657      4.537     19.146      0.000      77.973      95.759\n",
       "x27           82.1481      4.514     18.200      0.000      73.301      90.995\n",
       "x28           88.8719      4.472     19.871      0.000      80.106      97.638\n",
       "x29          114.8206      4.435     25.889      0.000     106.127     123.514\n",
       "x30          148.9165      4.274     34.843      0.000     140.539     157.294\n",
       "x31          134.3200      4.324     31.066      0.000     125.845     142.795\n",
       "x32           88.6181      4.367     20.294      0.000      80.059      97.177\n",
       "x33           53.8981      4.362     12.356      0.000      45.348      62.448\n",
       "x34           31.4560      4.362      7.211      0.000      22.905      40.007\n",
       "x35           15.6016      4.361      3.577      0.000       7.053      24.150\n",
       "x36           17.5696      4.142      4.242      0.000       9.450      25.689\n",
       "x37            7.8440      4.197      1.869      0.062      -0.383      16.071\n",
       "x38            4.3529      4.131      1.054      0.292      -3.744      12.450\n",
       "x39           11.6014      4.136      2.805      0.005       3.495      19.707\n",
       "x40           10.0786      4.121      2.445      0.014       2.000      18.157\n",
       "x41           15.7346      4.121      3.818      0.000       7.657      23.812\n",
       "==============================================================================\n",
       "Omnibus:                      593.168   Durbin-Watson:                   0.238\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1434.562\n",
       "Skew:                           0.169   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.365   Cond. No.                         31.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a fitted model \n",
    "lm1=sm.OLS(y_train, X_train).fit()\n",
    "predictions =lm1.predict(X_test)\n",
    "\n",
    "#print summary\n",
    "lm1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Spalte coeff gibt an, wie hoch der Zusammenhang der Variable mit der abhängigen y-Variablen (count_out) ist. Ein hoher Wert sagt aus, dass ein hoher Zusammenhang zwischen diesen beiden Variabeln besteht. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere Verbesserung dieses Prognosemodells könnte durch eine Polynomregression statt durch eine Lineare Regression erzielt werden. Diese wurde aber nicht weiter ausgeführt, da im Vergleich mit den anderen Prognosemodellen, andere Modelle schon eine bessere Prognosegenauigkeit erreicht haben und daher der Fokus mehr auf die Verbesserung dieser Modelle gelegt wurde.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineare Regression zum Vergleich\n",
    "\n",
    "Zum einfachen Vergleich wird nun noch eine reine lineare Regression erstellt. \n",
    "Als Unabhängige Variable X wird nur die Spalte Temperatur verwendet (abhängige Variable weiterhin\"count_out\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17401, 1) (17401,) (8560, 1) (8560,)\n",
      "Mean Absolute Error: 292.47451897229865\n",
      "Mean Squared Error: 132327.0645464576\n",
      "Root Mean Squared Error (RMSE): 363.7678717897687\n",
      "Results from LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False): \n",
      "r2=0.032 \n",
      "RMSLE=1.644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Trennen von Trainings- und Testdaten in unabhängige Variablen (X) und abhängige Variable (count_out y)\n",
    "# Nur die Temperaturspalte wird nicht bei Drop Coloum hinzugefügt. \n",
    "drop_cols = ['date', 'count_in', 'index', 'day_of_week', 'dewpoint', 'humidity', 'precipitation', 'pressure','windspeed', 'workingday', 'year', 'Season_Fall', 'Season_Spring', 'Season_Summer', 'hour_0', 'hour_1','hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12','hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22','weekday_Friday', 'weekday_Monday', 'weekday_Saturday', 'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday']\n",
    "y_cols =['count_out']\n",
    "feature_cols = [col for col in df_count.columns if (col not in y_cols) & (col not in drop_cols)]\n",
    "\n",
    "X_train = dataTrain[feature_cols]\n",
    "X_test = dataTest[feature_cols]\n",
    "\n",
    "y_train = dataTrain['count_out']\n",
    "y_test = dataTest['count_out']\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "#Instanziieren der Klasse \n",
    "lm = LinearRegression()\n",
    "\n",
    "#Modell trainieren \n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "#Vorhersage\n",
    "y_pred =lm.predict(X_test)\n",
    "\n",
    "#Metriken ausgeben\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "#R-Squared Wert berechnen\n",
    "#print('R-Squared Value:', lm.score(X_test, y_test))\n",
    "score_model(lm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann bei diesem Test sehen, dass die Lineare Regression allein mit der Temperatur im Verhältnis zu dem count_out weit aus schlechter performt, als die vorherige Multiple Lineare Regression bei der alle anderen Spalten auch mitbeachtet werden.\n",
    "\n",
    "Eine solche Lineare Regression könnte genutzt werden, wenn nur gewisse Hypthosen überprüft werden sollen z.B. welchen Einfluss die Temperatur auf die Ausleihvorgänge hat im Vergleich dazu welchen Einfluss eine andere Spalte auf die Ausleihvorgänge hat. Dann könnte für beide Fälle eine Lineare Regression erstellen und die Güte und die Koeffizienten miteinander vergleichen. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
